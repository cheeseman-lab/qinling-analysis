{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Preprocessing Params\n",
    "\n",
    "This notebook should be used to set up preprocessing params.\n",
    "Cells marked with <font color='red'>SET PARAMETERS</font> contain crucial variables that need to be set according to your specific experimental setup and data organization.\n",
    "Please review and modify these variables as needed before proceeding with the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from microfilm.microplot import Microimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lib.shared.configuration_utils import (\n",
    "    CONFIG_FILE_HEADER,\n",
    "    create_samples_df,\n",
    "    create_micropanel,\n",
    ")\n",
    "from lib.preprocess.preprocess import extract_metadata, convert_to_array\n",
    "from lib.preprocess.file_utils import get_sample_fps, get_tile_count_from_well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### Fixed parameters for preprocessing\n",
    "\n",
    "- `CONFIG_FILE_PATH`: Path to a Brieflow config file used during processing.\n",
    "- `ROOT_FP`: Path to root of Brieflow output directory.\n",
    "\n",
    "*Note: Paths can be absolute or relative to where workflows are run from.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE_PATH = \"config/config.yml\"\n",
    "ROOT_FP = \"brieflow_output/\"\n",
    "\n",
    "Path(CONFIG_FILE_PATH).parent.mkdir(parents=True, exist_ok=True)\n",
    "Path(ROOT_FP).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### Paths to dataframes with sample information\n",
    "- `SBS_SAMPLES_DF_FP`/`PHENOTYPE_SAMPLES_DF_FP`: Path to dataframe where SBS/phenotype samples location and metadata will be stored.\n",
    "- `SBS_COMBO_DF_FP`/`PHENOTYPE_COMBO_DF_FP`: Path to dataframe where SBS/phenotype sample metadata combinations will be stored.\n",
    "- `SBS_IMAGES_DIR_FP`/`PHENOTYPE_IMAGES_DIR_FP`: Path to directories with SBS/phenotype sample ND2 files. Set to `None` to ignore SBS/phenotype testing in this notebook.\n",
    "\n",
    "### Pattern configurations for metadata extraction\n",
    "\n",
    "#### SBS Configuration\n",
    "- `SBS_PATH_PATTERN`: Regex pattern to match directory structure of SBS files\n",
    "- `SBS_PATH_METADATA`: List of metadata to extract from file path\n",
    "    - Should include at least `\"plate\", \"well\", \"tile\", \"cycle\"` to extract SBS processing information\n",
    "- `SBS_METADATA_ORDER_TYPE`: Metadata order will be used to organize the file paths dataframe. Metadata types will be used to convert parsed information.\n",
    "\n",
    "#### Phenotype Configuration\n",
    "- `PHENOTYPE_PATH_PATTERN`: Regex pattern to match directory structure of phenotype files  \n",
    "- `PHENOTYPE_PATH_METADATA`: List of metadata to extract from file path\n",
    "    - Should include at least `\"plate\", \"well\", \"tile\"` to extract phenotype processing information\n",
    "- `PHENOTYPE_METADATA_ORDER_TYPE`: Metadata order will be used to organize the file paths dataframe. Metadata types will be used to convert parsed information.\n",
    "\n",
    "### Data Format and Organization\n",
    "\n",
    "- `SBS_DATA_FORMAT`/`PHENOTYPE_DATA_FORMAT`: \n",
    "  - `\"nd2\"`: Nikon ND2 files (most common)\n",
    "  - `\"tiff\"`: TIFF files (requires external metadata)\n",
    "  \n",
    "- `SBS_DATA_ORGANIZATION`/`PHENOTYPE_DATA_ORGANIZATION`:\n",
    "  - `\"tile\"`: Each file contains ONE field of view (FOV/position)\n",
    "    - Use when: Files like `plate1_well_A01_tile_001.nd2`, or `plate1_well_A01_tile_001.tiff`\n",
    "  - `\"well\"`: Each file contains MULTIPLE fields of view\n",
    "    - Use when: Files like `plate1_well_A01.nd2` with multiple positions inside\n",
    "\n",
    "*Notes:*\n",
    "- Paths can be absolute or relative to where workflows are run from\n",
    "- Each pattern should have the same number of capture groups as pieces of metadata listed\n",
    "- Metadata lists should be ordered to match the capture groups in their corresponding regex pattern\n",
    "- Numeric values (like cycle numbers) will automatically be converted to integers\n",
    "- For Brieflow to run effectively, each sample file path should have an associated plate/well. For single plate/well screens, manually add a plate/well to the file path dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to sample dataframes\n",
    "SBS_SAMPLES_DF_FP = \"config/sbs_samples.tsv\"\n",
    "PHENOTYPE_SAMPLES_DF_FP = \"config/phenotype_samples.tsv\"\n",
    "\n",
    "# Paths to combination dataframes\n",
    "SBS_COMBO_DF_FP = \"config/sbs_combo.tsv\"\n",
    "PHENOTYPE_COMBO_DF_FP = \"config/phenotype_combo.tsv\"\n",
    "\n",
    "# Paths to image directories\n",
    "SBS_IMAGES_DIR_FP = None\n",
    "PHENOTYPE_IMAGES_DIR_FP = None\n",
    "\n",
    "# SBS pattern configurations\n",
    "SBS_PATH_PATTERN = None\n",
    "SBS_PATH_METADATA = None\n",
    "SBS_METADATA_ORDER_TYPE = None\n",
    "\n",
    "# Phenotype pattern configurations\n",
    "PHENOTYPE_PATH_PATTERN = None\n",
    "PHENOTYPE_PATH_METADATA = None\n",
    "PHENOTYPE_METADATA_ORDER_TYPE = None\n",
    "\n",
    "# Data format and organization\n",
    "SBS_DATA_FORMAT = None \n",
    "SBS_DATA_ORGANIZATION = None\n",
    "PHENOTYPE_DATA_FORMAT = None\n",
    "PHENOTYPE_DATA_ORGANIZATION = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You must supply a working regex to the `SBS_PATH_PATTERN` and `PHENOTYPE_PATH_PATTERN` variables. If you don't have experience with regex, you can use the following LLM prompt to generate the patterns.\n",
    "\n",
    "*Enter into a basic LLM chatbot*: \n",
    "\n",
    "Given ND2 filenames from your experiment, generate regex patterns to extract metadata. Return only the regex patterns with no explanation.\n",
    "\n",
    "Example sbs filenames: **[ENTER YOUR EXAMPLE SBS FILES HERE WITH ANY UPSTREAM FOLDER STRUCTURE THAT IS RELEVANT TO THE METADATA]**\n",
    "\n",
    "Example phenotype filenames: **[ENTER YOUR EXAMPLE PHENOTYPE FILES HERE WITH ANY UPSTREAM FOLDER STRUCTURE THAT IS RELEVANT TO THE METADATA]**\n",
    "\n",
    "Required regex patterns (return these exact variable assignments):\n",
    "```python\n",
    "SBS_PATH_PATTERN = r\"...\"      # To match file path structure\n",
    "PHENOTYPE_PATH_PATTERN = r\"...\" # To match file path structure\n",
    "```\n",
    "\n",
    "The patterns should extract:\n",
    "1. SBS pattern:\n",
    "     - Plate number (after \"plate_\")\n",
    "     - Well ID (e.g., \"A1\", \"B2\")\n",
    "     - Tile number (after \"Points-\")\n",
    "     - Cycle number (after \"/c\")\n",
    "2. PHENOTYPE pattern:\n",
    "     - Plate number (after \"plate_\")\n",
    "     - Well ID (e.g., \"A1\", \"B2\")\n",
    "     - Tile number (after \"Points-\")\n",
    "\n",
    "Also provide the corresponding metadata lists and variable types:\n",
    "```python\n",
    "SBS_PATH_METADATA = [\"plate\", \"cycle\", \"well\", \"tile\"]\n",
    "PHENOTYPE_PATH_METADATA = [\"plate\", \"well\", \"tile\"]\n",
    "SBS_METADATA_ORDER_TYPE = {\"plate\": int, \"well\": str, \"tile\": int, \"cycle\": int}\n",
    "PHENOTYPE_METADATA_ORDER_TYPE = {\"plate\": int, \"well\": str, \"tile\": int}\n",
    "```\n",
    "\n",
    "Example patterns for reference:\n",
    "```python\n",
    "SBS_PATH_PATTERN = r\"plate_(\\d+)/c(\\d+)/.*_Wells-([A-Z]\\d+)_Points-(\\d+)__.*\"\n",
    "PHENOTYPE_PATH_PATTERN = r\"P(\\d+)_Pheno_20x_Wells-([A-Z]\\d+)_Points-(\\d+)__.*\"\n",
    "\n",
    "SBS_PATH_METADATA = [\"plate\", \"cycle\", \"well\", \"tile\"]\n",
    "PHENOTYPE_PATH_METADATA = [\"plate\", \"well\", \"tile\"]\n",
    "\n",
    "SBS_METADATA_ORDER_TYPE = {\"plate\": int, \"well\": str, \"tile\": int, \"cycle\": int}\n",
    "PHENOTYPE_METADATA_ORDER_TYPE = {\"plate\": int, \"well\": str, \"tile\": int}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sample DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SBS samples DataFrame\n",
    "sbs_samples = create_samples_df(\n",
    "    SBS_IMAGES_DIR_FP, SBS_PATH_PATTERN, SBS_PATH_METADATA, SBS_METADATA_ORDER_TYPE\n",
    ")\n",
    "sbs_samples.to_csv(SBS_SAMPLES_DF_FP, sep=\"\\t\", index=False)\n",
    "print(\"SBS samples:\")\n",
    "display(sbs_samples)\n",
    "\n",
    "# Create SBS wildcard combos based on data organization\n",
    "if SBS_DATA_ORGANIZATION == \"tile\":\n",
    "    sbs_wildcard_combos = sbs_samples[SBS_PATH_METADATA].drop_duplicates().astype(str)\n",
    "    sbs_wildcard_combos.to_csv(SBS_COMBO_DF_FP, sep=\"\\t\", index=False)\n",
    "    print(\"SBS wildcard combos (tile organization):\")\n",
    "    display(sbs_wildcard_combos)\n",
    "elif SBS_DATA_ORGANIZATION == \"well\" and len(sbs_samples) > 0:\n",
    "    print(\"SBS: Detecting tile count for well organization...\")\n",
    "    # Get tile count from a sample well\n",
    "    SBS_TILES = get_tile_count_from_well(\n",
    "        sbs_samples,\n",
    "        plate=sbs_samples[\"plate\"].iloc[0],\n",
    "        well=sbs_samples[\"well\"].iloc[0],\n",
    "        cycle=sbs_samples[\"cycle\"].iloc[0] if \"cycle\" in sbs_samples.columns else None,\n",
    "        verbose=True\n",
    "    )\n",
    "    print(f\"Detected {SBS_TILES} tiles per well for SBS\")\n",
    "    \n",
    "    # Generate combos with detected tile count\n",
    "    base_combos = sbs_samples[SBS_PATH_METADATA].drop_duplicates().astype(str)\n",
    "    tiles = [str(i) for i in range(SBS_TILES)]\n",
    "    sbs_wildcard_combos = pd.DataFrame([\n",
    "        {**row.to_dict(), \"tile\": tile}\n",
    "        for _, row in base_combos.iterrows()\n",
    "        for tile in tiles\n",
    "    ])\n",
    "    sbs_wildcard_combos.to_csv(SBS_COMBO_DF_FP, sep=\"\\t\", index=False)\n",
    "    print(\"SBS wildcard combos (well organization):\")\n",
    "    display(sbs_wildcard_combos)\n",
    "\n",
    "# Create phenotype samples DataFrame (always)\n",
    "phenotype_samples = create_samples_df(\n",
    "    PHENOTYPE_IMAGES_DIR_FP,\n",
    "    PHENOTYPE_PATH_PATTERN,\n",
    "    PHENOTYPE_PATH_METADATA,\n",
    "    PHENOTYPE_METADATA_ORDER_TYPE,\n",
    ")\n",
    "phenotype_samples.to_csv(PHENOTYPE_SAMPLES_DF_FP, sep=\"\\t\", index=False)\n",
    "print(\"Phenotype samples:\")\n",
    "display(phenotype_samples)\n",
    "\n",
    "# Create phenotype wildcard combos based on data organization\n",
    "if PHENOTYPE_DATA_ORGANIZATION == \"tile\":\n",
    "    phenotype_wildcard_combos = phenotype_samples[PHENOTYPE_PATH_METADATA].drop_duplicates().astype(str)\n",
    "    phenotype_wildcard_combos.to_csv(PHENOTYPE_COMBO_DF_FP, sep=\"\\t\", index=False)\n",
    "    print(\"Phenotype wildcard combos (tile organization):\")\n",
    "    display(phenotype_wildcard_combos)\n",
    "elif PHENOTYPE_DATA_ORGANIZATION == \"well\" and len(phenotype_samples) > 0:\n",
    "    print(\"Phenotype: Detecting tile count for well organization...\")\n",
    "    # Get tile count from a sample well\n",
    "    PHENOTYPE_TILES = get_tile_count_from_well(\n",
    "        phenotype_samples,\n",
    "        plate=phenotype_samples[\"plate\"].iloc[0],\n",
    "        well=phenotype_samples[\"well\"].iloc[0],\n",
    "        verbose=True\n",
    "    )\n",
    "    print(f\"Detected {PHENOTYPE_TILES} tiles per well for phenotype\")\n",
    "    \n",
    "    # Generate combos with detected tile count\n",
    "    base_combos = phenotype_samples[PHENOTYPE_PATH_METADATA].drop_duplicates().astype(str)\n",
    "    tiles = [str(i) for i in range(PHENOTYPE_TILES)]\n",
    "    phenotype_wildcard_combos = pd.DataFrame([\n",
    "        {**row.to_dict(), \"tile\": tile}\n",
    "        for _, row in base_combos.iterrows()\n",
    "        for tile in tiles\n",
    "    ])\n",
    "    phenotype_wildcard_combos.to_csv(PHENOTYPE_COMBO_DF_FP, sep=\"\\t\", index=False)\n",
    "    print(\"Phenotype wildcard combos (well organization):\")\n",
    "    display(phenotype_wildcard_combos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### Metadata Source Configuration\n",
    "\n",
    "- `SBS_METADATA_*`/`PHENOTYPE_METADATA_*`: Configuration for external metadata files containing positional and imaging metadata.\n",
    " - **For TIFF files**: Usually required (e.g., `coordinates.csv`, `metadata.tsv`)\n",
    " - **For ND2 files**: Usually set directories to `None` (metadata extracted from ND2 headers)\n",
    "\n",
    "**Metadata File Organization:**\n",
    "- `*_METADATA_IMAGES_DIR_FP`: Base directory containing metadata files\n",
    "- `*_METADATA_PATH_PATTERN`: Regex pattern to find metadata files\n",
    "- `*_METADATA_PATH_METADATA`: Metadata to extract from file paths\n",
    "- `*_METADATA_SAMPLES_DF_FP`: Where to save the metadata file inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set metadata extraction parameters\n",
    "SBS_METADATA_IMAGES_DIR_FP = None\n",
    "SBS_METADATA_PATH_PATTERN = None\n",
    "SBS_METADATA_PATH_METADATA = None\n",
    "SBS_METADATA_ORDER_TYPE = None\n",
    "SBS_METADATA_SAMPLES_DF_FP = None\n",
    "\n",
    "PHENOTYPE_METADATA_IMAGES_DIR_FP = None\n",
    "PHENOTYPE_METADATA_PATH_PATTERN = None\n",
    "PHENOTYPE_METADATA_PATH_METADATA = None\n",
    "PHENOTYPE_METADATA_ORDER_TYPE = None\n",
    "PHENOTYPE_METADATA_SAMPLES_DF_FP = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate SBS metadata samples table\n",
    "if SBS_METADATA_IMAGES_DIR_FP is not None:\n",
    "    print(\"Generating SBS metadata file inventory...\")\n",
    "    sbs_metadata_samples = create_samples_df(\n",
    "        SBS_METADATA_IMAGES_DIR_FP, \n",
    "        SBS_METADATA_PATH_PATTERN, \n",
    "        SBS_METADATA_PATH_METADATA, \n",
    "        SBS_METADATA_ORDER_TYPE\n",
    "    )\n",
    "    sbs_metadata_samples.to_csv(SBS_METADATA_SAMPLES_DF_FP, sep=\"\\t\", index=False)\n",
    "    print(\"SBS metadata files found:\")\n",
    "    display(sbs_metadata_samples)\n",
    "else:\n",
    "    print(\"SBS: No external metadata files - will extract from image files\")\n",
    "    sbs_metadata_samples = pd.DataFrame()\n",
    "\n",
    "# Generate phenotype metadata samples table\n",
    "if PHENOTYPE_METADATA_IMAGES_DIR_FP is not None:\n",
    "    print(\"\\nGenerating phenotype metadata file inventory...\")\n",
    "    phenotype_metadata_samples = create_samples_df(\n",
    "        PHENOTYPE_METADATA_IMAGES_DIR_FP,\n",
    "        PHENOTYPE_METADATA_PATH_PATTERN,\n",
    "        PHENOTYPE_METADATA_PATH_METADATA,\n",
    "        PHENOTYPE_METADATA_ORDER_TYPE\n",
    "    )\n",
    "    phenotype_metadata_samples.to_csv(PHENOTYPE_METADATA_SAMPLES_DF_FP, sep=\"\\t\", index=False)\n",
    "    print(\"Phenotype metadata files found:\")\n",
    "    display(phenotype_metadata_samples)\n",
    "else:\n",
    "    print(\"Phenotype: No external metadata files - will extract from ND2 files\")\n",
    "    phenotype_metadata_samples = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Metadata Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sbs_samples) > 0:\n",
    "    print(\"Testing SBS metadata extraction...\")\n",
    "    \n",
    "    # Get metadata file for this specific sample\n",
    "    if len(sbs_metadata_samples) > 0:\n",
    "        # Find matching metadata file\n",
    "        test_metadata_file = get_sample_fps(\n",
    "            sbs_metadata_samples,\n",
    "            plate=sbs_samples[\"plate\"].iloc[0],\n",
    "            cycle=sbs_samples[\"cycle\"].iloc[0] if \"cycle\" in sbs_samples.columns else None\n",
    "        )\n",
    "        print(f\"Using metadata file: {test_metadata_file}\")\n",
    "    else:\n",
    "        test_metadata_file = None  \n",
    "        print(\"No metadata files - extracting from image files\")\n",
    "    \n",
    "    # Extract metadata using unified function\n",
    "    test_sbs_metadata = extract_metadata(\n",
    "        sbs_samples[\"sample_fp\"].iloc[0],\n",
    "        plate=sbs_samples[\"plate\"].iloc[0],\n",
    "        well=sbs_samples[\"well\"].iloc[0],\n",
    "        tile=sbs_samples[\"tile\"].iloc[0] if \"tile\" in sbs_samples.columns else 0,\n",
    "        cycle=sbs_samples.get(\"cycle\", [None]).iloc[0],\n",
    "        data_format=SBS_DATA_FORMAT,\n",
    "        data_organization=SBS_DATA_ORGANIZATION,\n",
    "        metadata_file_path=test_metadata_file,\n",
    "        verbose=True\n",
    "    )\n",
    "    print(\"SBS test metadata:\")\n",
    "    display(test_sbs_metadata)\n",
    "\n",
    "# Test phenotype metadata extraction  \n",
    "if len(phenotype_samples) > 0:\n",
    "    print(\"\\nTesting phenotype metadata extraction...\")\n",
    "    \n",
    "    # Get metadata file for this specific sample (if any)\n",
    "    if len(phenotype_metadata_samples) > 0:\n",
    "        # Find matching metadata file\n",
    "        test_metadata_file = get_sample_fps(\n",
    "            phenotype_metadata_samples,\n",
    "            plate=phenotype_samples[\"plate\"].iloc[0],\n",
    "            round=phenotype_samples[\"round\"].iloc[0] if \"round\" in phenotype_samples.columns else None\n",
    "        )\n",
    "        print(f\"Using metadata file: {test_metadata_file}\")\n",
    "    else:\n",
    "        test_metadata_file = None \n",
    "        print(\"No metadata files - extracting from ND2 files\")\n",
    "    \n",
    "    # Extract metadata using unified function\n",
    "    test_phenotype_metadata = extract_metadata(\n",
    "        phenotype_samples[\"sample_fp\"].iloc[0],\n",
    "        plate=phenotype_samples[\"plate\"].iloc[0],\n",
    "        well=phenotype_samples[\"well\"].iloc[0],\n",
    "        tile=phenotype_samples[\"tile\"].iloc[0] if \"tile\" in phenotype_samples.columns else 0,\n",
    "        round=phenotype_samples[\"round\"].iloc[0] if \"round\" in phenotype_samples.columns else None,\n",
    "        data_format=PHENOTYPE_DATA_FORMAT,\n",
    "        data_organization=PHENOTYPE_DATA_ORGANIZATION,\n",
    "        metadata_file_path=test_metadata_file,\n",
    "        verbose=True\n",
    "    )\n",
    "    print(\"Phenotype test metadata:\")\n",
    "    display(test_phenotype_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### Image conversion\n",
    "\n",
    "- `SBS_CHANNEL_ORDER`/`PHENOTYPE_CHANNEL_ORDER`: Manually set channel order _if ND2 images are acquired as single channels, or there are multiple files for each tile (e.g. multiple rounds of phenotype images). Should be `None` if multichannel image files are acquired. The extracted channel names must match the values that will be displayed in the samples DataFrame channel column (e.g., `[\"DAPI\", \"GFP\", \"CY3\", \"CY5\", \"AF750\"]`).\n",
    "- `PHENOTYPE_ROUND_ORDER`: List of round numbers specifying the order in which to process phenotype image rounds. Should be `None` if there is only one round of phenotyping. For multiple rounds, specify the round numbers in the desired order (e.g., `[1, 2, 3]`). The round numbers must match the values in the samples DataFrame round column.\n",
    "\n",
    "**Note** For single-channel files, each file must contain a channel identifier that your regex can extract. For multichannel files, set the channel patterns to `None`. Metadata extraction is only performed on the first channel dimension for each tile. Please ensure the Dapi channel is displayed first!\n",
    "\n",
    "- `SBS_CHANNEL_ORDER_FLIP`/`PHENOTYPE_CHANNEL_ORDER_FLIP`: Whether or not to flip channel order when converting ND2->tiff. Should be `False` if channels are in a standard order (with Dapi first), or `True` if channels are reversed. This will only occur for multichannel ND2 files, for each individual ND2 file. Setting the channel order for single channel files is done by setting `SBS_CHANNEL_ORDER`/`PHENOTYPE_CHANNEL_ORDER` previously.\n",
    "\n",
    "**Note** Channel order can be checked with the test conversions below. Please ensure the Dapi channel is displayed first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBS_CHANNEL_ORDER = None\n",
    "PHENOTYPE_CHANNEL_ORDER = None\n",
    "PHENOTYPE_ROUND_ORDER = None\n",
    "SBS_CHANNEL_ORDER_FLIP = False\n",
    "PHENOTYPE_CHANNEL_ORDER_FLIP = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Image Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test SBS conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sbs_samples) > 0:\n",
    "    print(\"Testing SBS image conversion...\")\n",
    "    \n",
    "    # Get sample files based on data organization\n",
    "    if SBS_DATA_ORGANIZATION == \"tile\":\n",
    "        sbs_sample_files = get_sample_fps(\n",
    "            sbs_samples,\n",
    "            plate=sbs_samples[\"plate\"].iloc[0],\n",
    "            well=sbs_samples[\"well\"].iloc[0],\n",
    "            tile=sbs_samples[\"tile\"].iloc[0] if \"tile\" in sbs_samples.columns else 0,\n",
    "            cycle=sbs_samples[\"cycle\"].iloc[0] if \"cycle\" in sbs_samples.columns else None,\n",
    "            channel_order=SBS_CHANNEL_ORDER,\n",
    "        )\n",
    "    else:  # well organization\n",
    "        sbs_sample_files = get_sample_fps(\n",
    "            sbs_samples,\n",
    "            plate=sbs_samples[\"plate\"].iloc[0],\n",
    "            well=sbs_samples[\"well\"].iloc[0],\n",
    "            cycle=sbs_samples[\"cycle\"].iloc[0] if \"cycle\" in sbs_samples.columns else None,\n",
    "            channel_order=SBS_CHANNEL_ORDER,\n",
    "        )\n",
    "        \n",
    "    # Convert using unified function\n",
    "    sbs_image = convert_to_array(\n",
    "        sbs_sample_files,\n",
    "        data_format=SBS_DATA_FORMAT,\n",
    "        data_organization=SBS_DATA_ORGANIZATION,\n",
    "        position=0 if SBS_DATA_ORGANIZATION == \"well\" else None,\n",
    "        channel_order_flip=SBS_CHANNEL_ORDER_FLIP,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    print(f\"SBS converted image shape: {sbs_image.shape}\")\n",
    "    \n",
    "    # Display images\n",
    "    sbs_microimages = [Microimage(image) for image in sbs_image]\n",
    "    sbs_panel = create_micropanel(sbs_microimages, add_channel_label=False)\n",
    "    plt.title(\"SBS Test Conversion\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test phenotype conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(phenotype_samples) > 0:\n",
    "    print(\"Testing phenotype image conversion...\")\n",
    "    \n",
    "    # Get sample files based on data organization\n",
    "    if PHENOTYPE_DATA_ORGANIZATION == \"tile\":\n",
    "        phenotype_sample_files = get_sample_fps(\n",
    "            phenotype_samples,\n",
    "            plate=phenotype_samples[\"plate\"].iloc[0],\n",
    "            well=phenotype_samples[\"well\"].iloc[0],\n",
    "            tile=phenotype_samples[\"tile\"].iloc[0] if \"tile\" in phenotype_samples.columns else 0,\n",
    "            round_order=PHENOTYPE_ROUND_ORDER,\n",
    "            channel_order=PHENOTYPE_CHANNEL_ORDER,\n",
    "        )\n",
    "    else:  # well organization\n",
    "        phenotype_sample_files = get_sample_fps(\n",
    "            phenotype_samples,\n",
    "            plate=phenotype_samples[\"plate\"].iloc[0],\n",
    "            well=phenotype_samples[\"well\"].iloc[0],\n",
    "            round_order=PHENOTYPE_ROUND_ORDER,\n",
    "            channel_order=PHENOTYPE_CHANNEL_ORDER,\n",
    "        )\n",
    "      \n",
    "    # Convert using unified function\n",
    "    phenotype_image = convert_to_array(\n",
    "        phenotype_sample_files,\n",
    "        data_format=PHENOTYPE_DATA_FORMAT,\n",
    "        data_organization=PHENOTYPE_DATA_ORGANIZATION,\n",
    "        position=0 if PHENOTYPE_DATA_ORGANIZATION == \"well\" else None,\n",
    "        channel_order_flip=PHENOTYPE_CHANNEL_ORDER_FLIP,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Phenotype converted image shape: {phenotype_image.shape}\")\n",
    "    \n",
    "    # Display images\n",
    "    phenotype_microimages = [Microimage(image) for image in phenotype_image]\n",
    "    phenotype_panel = create_micropanel(phenotype_microimages, add_channel_label=False)\n",
    "    plt.title(\"Phenotype Test Conversion\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### Calculate illumination correction field\n",
    "\n",
    "- `SAMPLE_FRACTION`: Controls what percentage of images to use when calculating the illumination correction field (0.0-1.0). Using a smaller fraction (e.g., 0.2 = 20%) speeds up processing by randomly sampling only a subset of your images. Default is 1.0 (use all images). For reliable results, ensure your sample contains enough images to accurately represent illumination variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_FRACTION = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create config file with params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty config variable\n",
    "config = {}\n",
    "\n",
    "# Add all section\n",
    "config[\"all\"] = {\n",
    "    \"root_fp\": ROOT_FP,\n",
    "}\n",
    "\n",
    "# Add preprocess section\n",
    "config[\"preprocess\"] = {\n",
    "    # File paths\n",
    "    \"sbs_samples_fp\": SBS_SAMPLES_DF_FP,\n",
    "    \"sbs_combo_fp\": SBS_COMBO_DF_FP,\n",
    "    \"phenotype_samples_fp\": PHENOTYPE_SAMPLES_DF_FP,\n",
    "    \"phenotype_combo_fp\": PHENOTYPE_COMBO_DF_FP,\n",
    "    \n",
    "    # SBS configuration\n",
    "    \"sbs_data_format\": SBS_DATA_FORMAT,\n",
    "    \"sbs_data_organization\": SBS_DATA_ORGANIZATION,\n",
    "    \"sbs_channel_order\": SBS_CHANNEL_ORDER,\n",
    "    \"sbs_channel_order_flip\": SBS_CHANNEL_ORDER_FLIP,\n",
    "    \"sbs_metadata_samples_df_fp\": SBS_METADATA_SAMPLES_DF_FP,\n",
    "    \n",
    "    # Phenotype configuration\n",
    "    \"phenotype_data_format\": PHENOTYPE_DATA_FORMAT,\n",
    "    \"phenotype_data_organization\": PHENOTYPE_DATA_ORGANIZATION,\n",
    "    \"phenotype_channel_order\": PHENOTYPE_CHANNEL_ORDER,\n",
    "    \"phenotype_channel_order_flip\": PHENOTYPE_CHANNEL_ORDER_FLIP,\n",
    "    \"phenotype_round_order\": PHENOTYPE_ROUND_ORDER,\n",
    "    \"phenotype_metadata_samples_df_fp\": PHENOTYPE_METADATA_SAMPLES_DF_FP,\n",
    "\n",
    "    # Processing parameters\n",
    "    \"sample_fraction\": SAMPLE_FRACTION,\n",
    "}\n",
    "\n",
    "# Write the updated configuration back with markdown-style comments\n",
    "with open(CONFIG_FILE_PATH, \"w\") as config_file:\n",
    "    # Write the introductory markdown-style comments\n",
    "    config_file.write(CONFIG_FILE_HEADER)\n",
    "\n",
    "    # Dump the updated YAML structure, keeping markdown comments for sections\n",
    "    yaml.dump(config, config_file, default_flow_style=False, sort_keys=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brieflow_jebel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
